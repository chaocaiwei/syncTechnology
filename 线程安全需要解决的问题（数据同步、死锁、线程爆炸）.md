# 线程安全需要解决的问题（数据同步、死锁、线程爆炸）

## 线程同步
线程安全首要解决的问题就是竞态环境下，共享资源在多线程之间的数据同步问题。对于一些基本概念及加锁方式，可以参考我的[上一篇文章](https://juejin.im/post/5a48c49d518825772a4b53fe)。

归纳起来，解决数据同步，就是对不可重入的、涉及共享资源操作的核心代码段加锁，或者派发到同一串行队列当中。

### 通过对加锁方式实现同步

先来看看各种加锁方式的运行效率。

|加锁方法|平均耗时（纳秒/次）|
|------------------|-----------------------|
|OSSpinLock|62|
|dispatch_semaphore_t|75|
|pthread_mutex_t|82|
|pthread_rwlock_t|83|
|NSLock|96|
|NSRecursiveLock|151|
|NSConditionLock|257|
|@synchronized|395|
|dispatch_queue_t/SERIAL|85|
|dispatch_queue_t/CONCURRENT|94|
|dispatch_queue_t/global|46|
|NSOperationQueue|7871|

对于一般的互斥场景：

- `OSSpinLock`虽然运行效率最高，但由于优先级反转问题，一般极少使用。
- `dispatch_semaphore_t`、`pthread_mutex_t`、`NSLock`和GCD串行队列，这些同步方式的运行效率差别不大。
- 相同的锁pthread相关API更为高效。如果是跨平台开发，或者使用的是C++开发，或者对性能要求比较高，果断选择它。
- 互斥锁在使用时需要考虑是否可能递归调用。如果是，需要替换为递归锁。而递归锁需要耗费成倍的计算资源。
- `dispatch_semaphore_t `一般用于处理更为复杂的业务场景。信号量为1时，可以作为互斥锁使用。但一个线程持有的锁可以被其他线程释放
- `@synchronized`因为包含了可递归性质，而且需要生成和维护hash表，运行效率比较低。但它更为抽象。在一些不必过分关注运行效率的场合，可以不用费心一大堆锁对象，可读性也更强。值得注意的是传入的对象，最好是跟代码段相关的对象，而不是一概而论传入self。那样的话，如果整个类中有多处使用@synchronized，那么互相之前会出现冲突。
- `NSOperationQueue ` 在将maxConcurrentOperationCount设置为1的时候，也能达到一段代码互斥的效果。但是这种方法及其耗费性能，不推荐使用。
- GCD的同步队列应该算是最好的方案了，即兼顾了效率，在使用时也没有过多的顾虑。

除此之外，许多锁都有其独特的应用场景。具体可以参见[这里](https://juejin.im/post/5a48c49d518825772a4b53fe)。



## 死锁

### 线程/进程死锁

**死锁**是指多个线程因竞争资源而造成的一种僵局（互相等待），若无外力作用，这些进程都将无法向前推进。关于死锁问题可以参考[这篇文章](http://blog.csdn.net/ls5718/article/details/51896159)

一个经典的死锁场景，是在主线程上将代码块同步派发回住线程。这样形成了等待循环。主线程runloop等待代码块的执行，代码块因派发到主线程，需要等待runloop的调用

```
dispatch_sync(dispatch_get_main_queue(), ^{
        
});
```

#### 死锁产生的必要条件

产生死锁必须同时满足以下四个条件，只要其中任一条件不成立，死锁就不会发生。

- 互斥条件：进程要求对所分配的资源（如打印机）进行排他性控制，即在一段时间内某 资源仅为一个进程所占有。此时若有其他进程请求该资源，则请求进程只能等待。
- 不剥夺条件：进程所获得的资源在未使用完毕之前，不能被其他进程强行夺走，即只能 由获得该资源的进程自己来释放（只能是主动释放)。
- 请求和保持条件：进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源 已被其他进程占有，此时请求进程被阻塞，但对自己已获得的资源保持不放。
- 循环等待条件：存在一种进程资源的循环等待链，链中每一个进程已获得的资源同时被 链中下一个进程所请求




### 互斥锁使用中的死锁问题

一组线程中的所有线程都在等待被同组中另外一些线程占用的资源，这时，所有线程都因等待互斥量而被挂起，它们中的任何一个都不可能恢复运行，程序无法继续运行下去。这时就产生了死锁。Pthread函数库可以跟踪这种情形，最后一个线程试图调用pthread_mutex_lock()时会失败，并返回类型为EDEADLK的错误。

造成死锁的两种情形：

- 递归/嵌套加锁而没有使用递归锁类型


```
线程1

lockB.lock()
print("lockB in ")
lockA.lock()
print("lockA in lockB")
lockA.unlock()
lockB.unlock()
```
上述情形中，无论lockA与lockB是否是同一个锁，都会出现死锁现象。解决方法是将lockA、lockB其中任一锁设置或替换为递归锁。

- 线程1拥有A锁，请求获得B锁；线程2拥有B锁，请求获得A锁，出现死锁，最终导致的结果是互相等待。

```
线程1
lockA.lock()
print("lockA in ")
lockB.lock()
print("lockB in lockA")
lockB.unlock()
lockA.unlock()


线程2
lockB.lock()
print("lockB in ")
lockA.lock()
print("lockA in lockB")
lockA.unlock()
lockB.unlock()
```
这里即使将两个锁都换成递归锁，仍有发生死锁的可能。将两段代码分别放在两个线程中，重复执行3000遍，程序往往会停在某一次运行中。

#### 如何避免死锁
- 在需要递归调用的场合使用递归锁
- 每个线程都按照相同的顺序获得锁
- 为锁设置超时等待时间，超过等待时间则自动解锁
- 进行死锁检测。也就是使用trylock方法

```
- (BOOL)tryLock;
- (BOOL)lockBeforeDate:(NSDate *)limit;
```

## 线程爆炸
这里所说的`线程爆炸`指的是，因无限制的开启线程而造成的性能问题。苹果并没有任何文档表明，对同时运行或等待的线程数目有任何限制。但是，实验表明，一个程序中同时运行的线程是有限制的，超过这个限制之后，就必须等其他线程释放，才能开启新线程。

也就是说，当前线程总数达到或超过一定限制时。其他需要在新开启线程中执行的代码段就会卡住。造成一定的性能问题。

```
dispatch_queue_t     q1   = dispatch_get_global_queue(0, 0);
    for(int i = 0;i < 3000;i++){
        dispatch_async(q1, ^{
            NSLog(@" ===%d",i);
            sleep(3);
         });
     }
}
```
上述代码中，同一时间只能运行65个左右线程，3s后所有线程释放，另外65个线程才得以执行。

下述代码在swift中运行会几率卡死，而OC中貌似不会。原因应该与线程爆炸有关。有心的朋友可以验证一下。

```
let semt = DispatchSemaphore(value: 5)
let q1   = DispatchQueue.global()
for i in 0...67 {
    DispatchQueue.global().async {
        print(" ===\(i)")
        semt.wait()
        print("downLoad start \(0)  ===\(i)")
        q1.asyncAfter(deadline: .now() + .seconds(1)) {
            semt.signal()
            print("downLoad finish  ====\(i)")
        }
    }
}
```

### 3.1 如何避免线程爆炸

#### 3.1.1 有效的控制异步并行队列的使用

- 频繁地线程切换会消耗性能。只有对于比较耗时的操作、或者需要等待的任务时，才使用起步派发。
- 有效的管理我们所开辟的线程，而不是将所有需要异步执行的操作都派发到`dispatch_get_global_queue`。它只适用于那些临时的线程间切换操作，如网络请求完成之后，切换回住线程以刷新UI
- 对于某些相关联的操作，最好派发到同一队列中，并且为队列起个便于区分的名字。置于是同步队列还是异步队列，取决于业务中，所有操作是否都支持并行。

```
dispatch_queue_t  queue = dispatch_queue_create("my queue", DISPATCH_QUEUE_CONCURRENT);
```


#### 3.2 控制线程的最大并发数

我们并不希望线程无线增长，某些情况下我们需要对线程的最大并发数量加以控制。通常来说，有以下几种方式：

- NSOperationQueue的maxConcurrentOperationCount属性

```
NSOperationQueue *queue = [NSOperationQueue new];
queue.maxConcurrentOperationCount  = 5;
```
- 信号量

```
dispatch_semaphore_t semt = dispatch_semaphore_create(5);
dispatch_queue_t     q1   = dispatch_get_global_queue(0, 0);
for(int i = 0;i < 3000;i++){
    dispatch_async(q1, ^{
       
        dispatch_semaphore_wait(semt,DISPATCH_TIME_FOREVER);
        
        // do something
        
        dispatch_semaphore_signal(semt);
      
	});
}  
```



